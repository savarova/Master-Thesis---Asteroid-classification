{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf707598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reading in the spectroscopic and taxonomy data as well as the list of usable asteroids.\n",
    "\"\"\"\n",
    "asteroid_list = pd.read_excel('asteroids.xlsx')\n",
    "spectradata_full = pd.read_excel('gaia-dr3-sso-spectra.xlsx')\n",
    "taxonomy_full = pd.read_excel('EAR-simplified-taxonomy.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess the spectra by taking only asteroids that can be found in photometric dataset as well,\n",
    "and dropping all of the bad quality spectra.\n",
    "\"\"\"\n",
    "spectradata_full['inboth'] = spectradata_full['ast_num'].isin(asteroid_list).astype(int)\n",
    "spectradata = spectradata_full[spectradata_full.inboth != 0]\n",
    "spectradata.replace(-99.9, np.nan, inplace=True)\n",
    "spectradata = spectradata.dropna()\n",
    "spectradata_temp = spectradata[spectradata.no_of_1_flags == 0]\n",
    "spectradata_temp = spectradata[spectradata.no_of_2_flags == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21baa0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters that define which input variable group to run.\n",
    "\n",
    "'allspectra' can be either 0 - treat as one spectra, or 1 - divide into red and blue passbands\n",
    "'spec_slope_param' can be either 0 - run only spectra, 1 - run spectra + slopes, or 2 - run only slopes\n",
    "'onlyCXI' can be either 0 - run CXI and EI slopes, or 1 - run only CXI slopes\n",
    "'pca_param' can be either 0 - run nn in original data dimensions, or 1 - run nn in pca dimensions\n",
    "\"\"\"\n",
    "\n",
    "allspectra = 0 # if 0 treat as one spectra, if 1 treat as 2 blocks\n",
    "specslopparam = 1 # if 0 just spectra, if 1 both spectra and slope, if 2 only slope\n",
    "onlyCXI = 0 # remove EI slopes\n",
    "pcaparam = 0 # if 0 nn on spectra, if 1 nn on pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performing normalization and standardization of the spectra. For two-block spectra the red block is normalized to 1 at 682 nm.\n",
    "\"\"\"\n",
    "\n",
    "if allspectra == 0:\n",
    "    spectradata_asone = spectradata_temp[['ast_num', 'spectra 418', 'spectra 462', 'spectra 506', 'spectra 550', 'spectra 594', 'spectra 638', 'spectra 682', 'spectra 726', 'spectra 770']]\n",
    "    spectradata_asone.set_index('ast_num', drop = True, inplace=True)\n",
    "    print('Computing as one spectra')\n",
    "    \n",
    "    mean_asone = spectradata_asone.values.mean()\n",
    "    spectradata_asone_mean = spectradata_asone - mean_asone\n",
    "    std_asone = spectradata_asone.values.std(ddof=1)\n",
    "    spectra_all = spectradata_asone_mean / std_asone\n",
    "    \n",
    "    \n",
    "if allspectra == 1:\n",
    "\n",
    "    spectradata_blue = spectradata_temp[['ast_num', 'spectra 418', 'spectra 462', 'spectra 506', 'spectra 550', 'spectra 594']]\n",
    "    spectradata_blue.set_index('ast_num', drop = True, inplace=True)\n",
    "    spectradata_red = spectradata_temp[['ast_num', 'spectra 638', 'spectra 682', 'spectra 726', 'spectra 770']]\n",
    "    spectradata_red.set_index('ast_num', drop = True, inplace=True)\n",
    "    print('Computing as red and blue blocks')\n",
    "\n",
    "    spectradata_red_norm = spectradata_red.copy()\n",
    "    for index, row in spectradata_red.iterrows():\n",
    "        spectradata_red_norm.loc[index] = spectradata_red.loc[index] / (row['spectra 682'])\n",
    "\n",
    "    mean_blue = spectradata_blue.values.mean()\n",
    "    mean_red = spectradata_red.values.mean()\n",
    "\n",
    "    spectradata_blue_mean = spectradata_blue - mean_blue\n",
    "    spectradata_red_mean = spectradata_red - mean_red\n",
    "\n",
    "    std_blue = spectradata_blue.values.std(ddof=1)\n",
    "    std_red = spectradata_red.values.std(ddof=1)\n",
    "\n",
    "    spectradata_blue_stanrd = spectradata_blue_mean / std_blue\n",
    "    spectradata_red_stanrd = spectradata_red_mean / std_red\n",
    "\n",
    "    spectra_all = pd.concat([spectradata_blue_stanrd, spectradata_red_stanrd], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bae280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reading in the ellipsoid inversion photometric data.\n",
    "\"\"\"\n",
    "\n",
    "with open('/home/euvarova/Work/University/PSR/2023/EI_mcst1_new.txt', 'r') as f:\n",
    "    slopefile = f.readlines()\n",
    "\n",
    "slopes_list = []\n",
    "slopes_err_list = []\n",
    "slope_ast_list = []\n",
    "period_list = []\n",
    "\n",
    "    \n",
    "for row in slopefile:\n",
    "    slope_ast_list.append(int(row.strip().split()[0]))\n",
    "    slopes_list.append(float(row.strip().split()[14]))\n",
    "    slopes_err_list.append(float(row.strip().split()[15]))\n",
    "\n",
    "    \n",
    "slopes_org = pd.DataFrame()\n",
    "slopes_org['ast_num'] = slope_ast_list\n",
    "slopes_org['slope_ei'] = slopes_list\n",
    "slopes_org['err_ei'] = slopes_err_list\n",
    "slopes_org.set_index('ast_num', drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5348d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reading in the convex inversion photometric data and join it with the ellipsoid inversion data.\n",
    "\"\"\"\n",
    "\n",
    "with open('/home/euvarova/Work/University/PSR/2023/CXI_mcst1_rms_forLiisa.txt', 'r') as f:\n",
    "    slopefile = f.readlines()\n",
    "\n",
    "slopes_list = []\n",
    "slopes_err_list = []\n",
    "slope_ast_list = []\n",
    "rms_list = []\n",
    "    \n",
    "for row in slopefile:\n",
    "    slope_ast_list.append(int(row.strip().split()[0]))\n",
    "    rms_list.append(float(row.strip().split()[1]))\n",
    "    slopes_list.append(float(row.strip().split()[12]))\n",
    "    slopes_err_list.append(float(row.strip().split()[13]))\n",
    "    \n",
    "\n",
    "slopes_temp = pd.DataFrame()\n",
    "slopes_temp['ast_num'] = slope_ast_list \n",
    "slopes_temp['rms_cxi'] = rms_list\n",
    "slopes_temp['slope_cxi'] = slopes_list\n",
    "slopes_temp['err_cxi'] = slopes_err_list\n",
    "slopes_temp.set_index('ast_num', drop = True, inplace=True)\n",
    "\n",
    "slopes_org = slopes_org.join(slopes_temp, how = 'inner')\n",
    "slopes_org = slopes_org[slopes_org.rms_cxi >= 0]\n",
    "slopes = slopes_org.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec99b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Removing all photometric slopes MCMC sd over 0.3 and rms over 0.06\n",
    "\"\"\"\n",
    "\n",
    "slopes = slopes[slopes['err_ei'] < 0.3]\n",
    "slopes = slopes[slopes['err_cxi'] < 0.3]\n",
    "\n",
    "slopes = slopes[slopes['rms_cxi'] < 0.06]\n",
    "\n",
    "slopes = slopes.drop(['err_ei'], axis=1)\n",
    "slopes = slopes.drop(['err_cxi'], axis=1)\n",
    "slopes = slopes.drop(['rms_cxi'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64de029",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performing normalization and standardization for the photometric slopes.\n",
    "\"\"\"\n",
    "\n",
    "mean_slopes_ei = slopes['slope_ei'].values.mean()\n",
    "mean_slopes_cxi = slopes['slope_cxi'].values.mean()\n",
    "\n",
    "slopes_mean_ei = slopes['slope_ei'] - mean_slopes_ei\n",
    "slopes_mean_cxi = slopes['slope_cxi'] - mean_slopes_cxi\n",
    "\n",
    "std_slopes_ei = slopes['slope_ei'].values.std(ddof=1)\n",
    "std_slopes_cxi = slopes['slope_cxi'].values.std(ddof=1)\n",
    "\n",
    "slopes_stanrd_ei = slopes_mean_ei / std_slopes_ei\n",
    "slopes_stanrd_cxi = slopes_mean_cxi / std_slopes_cxi\n",
    "\n",
    "slopes_stanrd = pd.concat([slopes_stanrd_ei,slopes_stanrd_cxi], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcc240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combining the standardized spectra and the standardized slopes.\n",
    "\"\"\"\n",
    "\n",
    "spectra_slopes = spectra_all.join(slopes_stanrd, how = 'inner')\n",
    "\n",
    "if specslopparam == 2:\n",
    "    if onlyCXI == 0:\n",
    "        spectra_slopes = slopes_stanrd.copy()\n",
    "    elif onlyCXI == 1:\n",
    "        spectra_slopes = slopes_stanrd['slope_cxi'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c39c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating a taxonomy dataframe with only asteroid numbers and classes.\n",
    "\"\"\"\n",
    "\n",
    "taxonomy_temp = pd.DataFrame()\n",
    "taxonomy_temp['Unified class'] = taxonomy_full['Unified class'].copy()\n",
    "taxonomy_temp.index = taxonomy_full['Asteroid number']\n",
    "taxonomy_temp.drop(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classifying those asteroids that had Tholen E, M, P classes in their 'Unified class' -column as their\n",
    "respective B-dM or Bus classes. Since there are multiple B-dM and Bus taxonomy colunmns, we check all\n",
    "of them. If the asteroid has not been classified by Bus or B-dM, we classify the asteroid as X. \n",
    "\"\"\"\n",
    "\n",
    "lst = []\n",
    "temp=[]\n",
    "\n",
    "taxonomy_full_ind = taxonomy_full[['Asteroid number', 'BUS CLASS', 'S3OS2 CLASS BB', 'BUS DEMEO CLASS']].copy()\n",
    "taxonomy_full_ind.set_index('Asteroid number', drop = True, inplace=True)\n",
    "\n",
    "for cls in ['E', 'M', 'P']:\n",
    "    lst.append(taxonomy_temp.loc[taxonomy_temp['Unified class'] == cls].index.to_list())\n",
    "    \n",
    "lst_flat = [item for sublist in lst for item in sublist]\n",
    "\n",
    "for i in taxonomy_temp.index:\n",
    "    if i in lst_flat:\n",
    "        if not pd.isna(taxonomy_full_ind.loc[i]['BUS DEMEO CLASS']):\n",
    "            temp.append(taxonomy_full_ind.loc[i]['BUS DEMEO CLASS'])\n",
    "        elif not pd.isna(taxonomy_full_ind.loc[i]['S3OS2 CLASS BB']):\n",
    "            temp.append(taxonomy_full_ind.loc[i]['S3OS2 CLASS BB'])\n",
    "        elif not pd.isna(taxonomy_full_ind.loc[i]['BUS CLASS']):\n",
    "            temp.append(taxonomy_full_ind.loc[i]['BUS CLASS'])    \n",
    "        else:\n",
    "            temp.append('X')\n",
    "    else:\n",
    "        temp.append(taxonomy_temp.loc[i]['Unified class'])\n",
    "        \n",
    "taxonomy_temp['Unified class'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combining subgroups of S, C and X spectra under one name to simplify the labeling\n",
    "\"\"\"\n",
    "\n",
    "temp = []\n",
    "for cl in taxonomy_temp['Unified class']:\n",
    "    if cl == 'Sk' or cl == 'Sr' or cl == 'Sq' or cl == 'Sa' or cl == 'Sv' or cl == 'Sl':\n",
    "        temp.append('S')\n",
    "    elif cl == 'Xe' or cl == 'Xc' or cl == 'Xk':\n",
    "        temp.append('X')\n",
    "    elif cl == 'Ch' or cl == 'Cg' or cl == 'Cb' or cl == 'Cgh' or cl == 'G' or cl == 'F' or cl == 'B':\n",
    "        temp.append('C')\n",
    "    else:\n",
    "        temp.append(cl)\n",
    "        \n",
    "taxonomy_temp['Main class'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc0f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performing PCA. The PCA is not performed for groups with only slopes, due to their low dimensionality.\n",
    "\"\"\"\n",
    "if specslopparam == 0:\n",
    "\n",
    "    model = PCA(n_components = 4)\n",
    "    fit = model.fit(spectra_all)\n",
    "    pc = model.fit_transform(spectra_all)\n",
    "\n",
    "    principal_spectra_all = pd.DataFrame(data = pc, columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4'], index = spectradata_temp['ast_num'])\n",
    "\n",
    "elif specslopparam == 1:\n",
    "\n",
    "    model = PCA(n_components = 4)\n",
    "    fit = model.fit(spectra_slopes)\n",
    "    pc = model.fit_transform(spectra_slopes)\n",
    "\n",
    "    principal_spectra_slopes = pd.DataFrame(data = pc, columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4'], index = spectra_slopes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14640b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checking the explained variation and eigendata.\n",
    "\"\"\"\n",
    "\n",
    "if specslopparam == 0:\n",
    "    \n",
    "    print('Explained variation per principal component: {}'.format(model.explained_variance_ratio_))\n",
    "    eigenvectors = model.components_\n",
    "    eigendata = pd.DataFrame(eigenvectors, columns = spectra_all.columns)\n",
    "    print(eigendata)\n",
    "\n",
    "if specslopparam == 1:\n",
    "    \n",
    "    print('Explained variation per principal component: {}'.format(model.explained_variance_ratio_))\n",
    "    eigenvectors = model.components_\n",
    "    eigendata = pd.DataFrame(eigenvectors, columns = spectra_slopes.columns)\n",
    "    print(eigendata)\n",
    "\n",
    "if specslopparam == 2:\n",
    "    \n",
    "    if onlyCXI == 0:\n",
    "        eigendata = pd.DataFrame(eigenvectors, columns = spectra_slopes.columns)\n",
    "        print(eigendata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21601bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plotting the photometric slope histograms to see how the taxonomic classes distribute.\n",
    "\"\"\"\n",
    "\n",
    "SCXDastlist = []\n",
    "SCXDclasslist = []\n",
    "\n",
    "for index, row in taxonomy_temp.iterrows():\n",
    "    if row['Main class'] == 'S' or row['Main class'] == 'C' or row['Main class'] == 'X' or row['Main class'] == 'D':\n",
    "        SCXDastlist.append(index)\n",
    "        SCXDclasslist.append(row['Main class'])\n",
    "        \n",
    "SCXDdf = pd.DataFrame()\n",
    "SCXDdf['ast'] = SCXDastlist\n",
    "SCXDdf['class'] = SCXDclasslist\n",
    "SCXDdf.set_index('ast', drop = True, inplace=True)\n",
    "\n",
    "SCXDdf_slopes = SCXDdf.join(slopes_org, how = 'inner')\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "slopehist = SCXDdf_slopes.hist(column='slope_cxi', by = 'class', bins = 20, edgecolor='black', sharex = True)\n",
    "for ax in slopehist.flatten():\n",
    "    ax.set_xlabel(\"CXI slope value\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Join the taxonomy classes with the spectra, slopes and spectra + slopes dataframes in their original and\n",
    "PCA dimensionalities.\n",
    "\"\"\"\n",
    "if specslopparam == 0:\n",
    "    taxonomy_spectra_pca = taxonomy_temp.join(principal_spectra_all, how = 'inner')\n",
    "    taxonomy_spectra = taxonomy_temp.join(spectra_all, how = 'inner')\n",
    "\n",
    "elif specslopparam == 1:\n",
    "    taxonomy_spectra_slopes_pca = taxonomy_temp.join(principal_spectra_slopes, how = 'inner')\n",
    "    taxonomy_spectra_slopes = taxonomy_temp.join(spectra_slopes, how = 'inner')\n",
    "    \n",
    "elif specslopparam == 2:\n",
    "    taxonomy_slopes = taxonomy_temp.join(spectra_slopes, how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ed9c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if specslopparam == 1:\n",
    "\n",
    "    plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "    size = 24\n",
    "\n",
    "    #---------------------------\n",
    "    #1VS2\n",
    "    fig, ax=plt.subplots(dpi = 200)\n",
    "    sns.scatterplot(data = taxonomy_spectra_slopes_pca, x = 'principal component 1', y = 'principal component 2', hue = 'Main class', s=size, ax=ax)\n",
    "    ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "    #---------------------------\n",
    "    #1VS3\n",
    "    fig, ax=plt.subplots(dpi = 200)\n",
    "    sns.scatterplot(data = taxonomy_spectra_slopes_pca, x = 'principal component 1', y = 'principal component 3', hue = 'Main class', s=size, ax=ax)\n",
    "    ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "    #---------------------------\n",
    "    #1VS4\n",
    "    fig, ax=plt.subplots(dpi = 200)\n",
    "    sns.scatterplot(data = taxonomy_spectra_slopes_pca, x = 'principal component 1', y = 'principal component 4', hue = 'Main class', s=size,ax=ax)\n",
    "    ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_ylim(-2,2)\n",
    "    plt.show()\n",
    "    #---------------------------\n",
    "    #2VS3\n",
    "    fig, ax=plt.subplots(dpi = 200)\n",
    "    sns.scatterplot(data = taxonomy_spectra_slopes_pca, x = 'principal component 2', y = 'principal component 3', hue = 'Main class', s=size, ax=ax)\n",
    "    ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_ylim(-2,2)\n",
    "    plt.show()\n",
    "    #---------------------------\n",
    "    #2VS4\n",
    "    fig, ax=plt.subplots(dpi = 200)\n",
    "    sns.scatterplot(data = taxonomy_spectra_slopes_pca, x = 'principal component 2', y = 'principal component 4', hue = 'Main class', s=size, ax=ax)\n",
    "    ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_ylim(-2,2)\n",
    "    plt.show()\n",
    "    #---------------------------\n",
    "    #3VS4\n",
    "    fig, ax=plt.subplots(dpi = 200)\n",
    "    sns.scatterplot(data = taxonomy_spectra_slopes_pca, x = 'principal component 3', y = 'principal component 4', hue = 'Main class', s=size, ax=ax)\n",
    "    ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_ylim(-2,2)\n",
    "    plt.show()\n",
    "    #---------------------------\n",
    "\n",
    "if specslopparam == 2:\n",
    "    if onlyCXI == 0:\n",
    "\n",
    "        plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "        size = 24\n",
    "\n",
    "        fig, ax=plt.subplots(dpi = 200)\n",
    "        sns.scatterplot(data = taxonomy_slopes_pca, x = 'principal component 1', y = 'principal component 2', hue = 'Main class', s=size, ax=ax)\n",
    "        ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Encode taxonomy classes as numerical data for the neural network.\n",
    "\"\"\"\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "if pcaparam == 0:\n",
    "    if specslopparam == 0:\n",
    "        taxonomy_spectra['num_class']= label_encoder.fit_transform(taxonomy_spectra['Main class'])\n",
    "\n",
    "    elif specslopparam == 1:\n",
    "        taxonomy_spectra_slopes['num_class']= label_encoder.fit_transform(taxonomy_spectra_slopes['Main class'])\n",
    "\n",
    "    elif specslopparam == 2:\n",
    "        taxonomy_slopes['num_class']= label_encoder.fit_transform(taxonomy_slopes['Main class'])\n",
    "        \n",
    "if pcaparam == 1:    \n",
    "    if specslopparam == 0:\n",
    "        taxonomy_spectra_pca['num_class']= label_encoder.fit_transform(taxonomy_spectra_pca['Main class'])\n",
    "\n",
    "    elif specslopparam == 1:\n",
    "        taxonomy_spectra_slopes_pca['num_class']= label_encoder.fit_transform(taxonomy_spectra_slopes_pca['Main class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f8f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Choosing only taxonomic groups C, S, X, and class D to look at.\n",
    "\"\"\"\n",
    "\n",
    "if pcaparam == 0:\n",
    "    if specslopparam == 0:\n",
    "        taxonomy_spectra_SCX = taxonomy_spectra[(taxonomy_spectra['Main class'] == 'S') | (taxonomy_spectra['Main class'] == 'C') | (taxonomy_spectra['Main class'] == 'D') | (taxonomy_spectra['Main class'] == 'X')]\n",
    "\n",
    "    elif specslopparam == 1:\n",
    "        taxonomy_spectra_slopes_SCX = taxonomy_spectra_slopes[(taxonomy_spectra_slopes['Main class'] == 'S') | (taxonomy_spectra_slopes['Main class'] == 'C') | (taxonomy_spectra_slopes['Main class'] == 'D') | (taxonomy_spectra_slopes['Main class'] == 'X')]\n",
    "        \n",
    "    elif specslopparam == 2:\n",
    "        taxonomy_slopes_SCX = taxonomy_slopes[(taxonomy_slopes['Main class'] == 'S') | (taxonomy_slopes['Main class'] == 'C') | (taxonomy_slopes['Main class'] == 'D') | (taxonomy_slopes['Main class'] == 'X')]\n",
    "        \n",
    "if pcaparam == 1:\n",
    "    if specslopparam == 0:\n",
    "        taxonomy_spectra_SCX_pca = taxonomy_spectra_pca[(taxonomy_spectra_pca['Main class'] == 'S') | (taxonomy_spectra_pca['Main class'] == 'C') | (taxonomy_spectra_pca['Main class'] == 'D') | (taxonomy_spectra_pca['Main class'] == 'X')]\n",
    "\n",
    "    elif specslopparam == 1:\n",
    "        taxonomy_spectra_slopes_pca_SCX = taxonomy_spectra_slopes_pca[(taxonomy_spectra_slopes_pca['Main class'] == 'S') | (taxonomy_spectra_slopes_pca['Main class'] == 'C') | (taxonomy_spectra_slopes_pca['Main class'] == 'D') | (taxonomy_spectra_slopes_pca['Main class'] == 'X')]\n",
    "        \n",
    "    elif specslopparam == 2:\n",
    "        if onlyCXI == 0:\n",
    "            taxonomy_slopes_pca_SCX = taxonomy_slopes_pca[(taxonomy_slopes_pca['Main class'] == 'S') | (taxonomy_slopes_pca['Main class'] == 'C') | (taxonomy_slopes_pca['Main class'] == 'D') | (taxonomy_slopes_pca['Main class'] == 'X')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e03e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining data (x), labels (y) and asteroid numbers (z) for the neural network.\n",
    "\"\"\"\n",
    "\n",
    "if pcaparam == 0:\n",
    "    if specslopparam == 0:\n",
    "        x = taxonomy_spectra_SCX.drop(['Unified class', 'Main class', 'num_class'], axis=1)\n",
    "        y = taxonomy_spectra_SCX['num_class']\n",
    "        z = taxonomy_spectra_SCX.index\n",
    "\n",
    "    elif specslopparam == 1:\n",
    "        x = taxonomy_spectra_slopes_SCX.drop(['Unified class', 'Main class', 'num_class'], axis=1)\n",
    "        y = taxonomy_spectra_slopes_SCX['num_class']\n",
    "        z = taxonomy_spectra_slopes_SCX.index\n",
    "\n",
    "    elif specslopparam == 2:\n",
    "        x = taxonomy_slopes_SCX.drop(['Unified class', 'Main class', 'num_class'], axis=1)\n",
    "        y = taxonomy_slopes_SCX['num_class']\n",
    "        z = taxonomy_slopes_SCX.index\n",
    "        \n",
    "if pcaparam == 1:\n",
    "    if specslopparam == 0:\n",
    "        x = taxonomy_spectra_SCX_pca.drop(['Unified class', 'Main class', 'num_class'], axis=1)\n",
    "        y = taxonomy_spectra_SCX_pca['num_class']\n",
    "        z = taxonomy_spectra_SCX_pca.index\n",
    "\n",
    "    elif specslopparam == 1:\n",
    "        x = taxonomy_spectra_slopes_pca_SCX.drop(['Unified class', 'Main class', 'num_class'], axis=1)      \n",
    "        y = taxonomy_spectra_slopes_pca_SCX['num_class']\n",
    "        z = taxonomy_spectra_slopes_pca_SCX.index\n",
    "\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "z = z.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18808c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining number of classes for the network depending on the data group we're using.\n",
    "\"\"\"\n",
    "\n",
    "if pcaparam == 0:\n",
    "    if specslopparam == 0:\n",
    "        num_classes = len(taxonomy_spectra['Main class'].unique())\n",
    "    elif specslopparam == 1:\n",
    "        num_classes = len(taxonomy_spectra_slopes['Main class'].unique())\n",
    "    elif specslopparam == 2:\n",
    "        num_classes = len(taxonomy_slopes['Main class'].unique())\n",
    "if pcaparam == 1:\n",
    "    if specslopparam == 0:\n",
    "        num_classes = len(taxonomy_spectra_pca['Main class'].unique())\n",
    "    elif specslopparam == 1:\n",
    "        num_classes = len(taxonomy_spectra_slopes_pca['Main class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66447de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using class spectradataset to tie together data and labels for shuffling, and to allow data extraction\n",
    "during the NN training.\n",
    "\"\"\"\n",
    "\n",
    "class spectradataset(Dataset):\n",
    "    def __init__(self, x, y, z):\n",
    "        self.x = torch.tensor(x, dtype = torch.float32)\n",
    "        self.y = torch.tensor(y, dtype = torch.int64)\n",
    "        self.z = torch.tensor(z, dtype = torch.int64)\n",
    "        self.length = self.x.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = dict()\n",
    "        item[\"spectra\"] = self.x[idx]\n",
    "        item[\"labels\"] = self.y[idx]\n",
    "        item[\"astnum\"] = self.z[idx] \n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92af0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining the training, validation and test datasets and turning them into dataloaders.\n",
    "\"\"\"\n",
    "\n",
    "train_dataset = spectradataset(x, y, z)\n",
    "train_len = int(len(train_dataset) * 0.8)\n",
    "\n",
    "train_set, test_set = random_split(train_dataset, [train_len, len(train_dataset)-train_len])\n",
    "\n",
    "val_len = int(len(train_set)*0.25)\n",
    "val_set, train_set = random_split(train_set, [val_len, len(train_set)-val_len])\n",
    "\n",
    "train_loader = DataLoader(dataset = train_set, shuffle = True, batch_size = batch_size)\n",
    "val_loader = DataLoader(dataset = val_set, shuffle = False, batch_size = len(val_set))\n",
    "test_loader = DataLoader(dataset = test_set, shuffle = False, batch_size = len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed326d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining a simple feed-forward neural network.\n",
    "\"\"\"\n",
    "\n",
    "class FFNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 32)\n",
    "        self.layer2 = nn.Linear(32, num_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.layer2(y)        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ead74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to train and validate the NN model. After training the fuction runs the model on a test set\n",
    "to get the final accuracy.\n",
    "\"\"\"\n",
    "\n",
    "def runtrainNN(train_loader, val_loader, test_loader, x, num_classes):\n",
    "\n",
    "    input_size = x.shape[1]\n",
    "    num_epochs = 250\n",
    "    batch_size = 10\n",
    "    learning_rate = 0.001 \n",
    "    n_total_steps = len(train_loader)\n",
    "    \n",
    "    #--- set up ---\n",
    "    model = FFNN(input_size, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "\n",
    "    acc_temp = []\n",
    "    epoch_temp = []\n",
    "    old_val_acc = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_acc = 0\n",
    "\n",
    "        for i, items in enumerate(train_loader):\n",
    "            n_samples = 0\n",
    "            n_correct = 0\n",
    "            spectra = items['spectra']\n",
    "            labels = items['labels']\n",
    "\n",
    "            #--- forward pass training ---\n",
    "            outputs = model(spectra)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predictions = torch.max(outputs,1)\n",
    "            n_samples = labels.shape[0]\n",
    "            n_correct = (predictions == labels).sum().item()\n",
    "            total_acc += n_correct\n",
    "\n",
    "            #--- backward and optimize ---\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #--- validation ---\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "\n",
    "        for items in val_loader:\n",
    "            spectra = items['spectra']\n",
    "            labels = items['labels']\n",
    "            outputs = model(spectra)\n",
    "            _, predictions = torch.max(outputs,1)\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "        acc_val = 100 * (n_correct / n_samples)\n",
    "\n",
    "        #--- forced break ---\n",
    "        if acc_val < old_val_acc:\n",
    "            break\n",
    "        old_val_acc = acc_val\n",
    "        acc_temp.append(total_acc/x.shape[0])\n",
    "        epoch_temp.append(epoch)\n",
    "        \n",
    "    #--- test ---        \n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "\n",
    "        for items in test_loader:\n",
    "            astnum = items['astnum']\n",
    "            spectra = items['spectra'][astnum<20000]\n",
    "            labels = items['labels'][astnum<20000]\n",
    "            outputs = model(spectra)\n",
    "            _, predictions = torch.max(outputs,1)\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "        acc = 100 * (n_correct / n_samples)\n",
    "        \n",
    "        return acc, model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd037c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running the model either 50 or 100 times and printing the statistics.\n",
    "\"\"\"\n",
    "\n",
    "results = []\n",
    "for i in range(100):\n",
    "    result, model, predictions = runtrainNN(train_loader, val_loader, test_loader, x, num_classes)\n",
    "    results.append(result) \n",
    "    \n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c478da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the confusion matrix to appraise the model. \n",
    "\"\"\"\n",
    "\n",
    "for i, item in enumerate(test_loader):\n",
    "    X_test = item['spectra'][astnum<20000].numpy()\n",
    "    y_test = item['labels'][astnum<20000].numpy()\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['C', 'D', 'S', 'X'])\n",
    "disp.plot(cmap = 'BuPu')\n",
    "\n",
    "if specslopparam == 2:\n",
    "    if pcaparam == 0:\n",
    "        if onlyCXI == 1:\n",
    "            plt.title('CXI Slopes (Group XIII)')\n",
    "        else:\n",
    "            plt.title('CXI and EI Slopes (Group XIV)')\n",
    "    if pcaparam == 1:\n",
    "        plt.title('CXI and EI Slopes, PCA')\n",
    "\n",
    "else:\n",
    "    if allspectra == 0:\n",
    "        if pcaparam == 0:\n",
    "            if specslopparam == 0:\n",
    "                plt.title('Spectra as one block (Group I)')\n",
    "            if specslopparam == 1:\n",
    "                if onlyCXI == 0:\n",
    "                    plt.title('CXI and EI Slopes + Spectra as one block (Group IX)')\n",
    "                if onlyCXI == 1:\n",
    "                    plt.title('CXI Slopes + Spectra as one block (Group V)')\n",
    "        if pcaparam == 1:\n",
    "            if specslopparam == 0:\n",
    "                plt.title('Spectra as one block, PCA (Group II)')\n",
    "            if specslopparam == 1:\n",
    "                if onlyCXI == 0:\n",
    "                    plt.title('CXI and EI Slopes + Spectra as one block, PCA (Group X)')\n",
    "                if onlyCXI == 1:\n",
    "                    plt.title('CXI Slopes + Spectra as one block, PCA (Group VI)')\n",
    "\n",
    "    if allspectra == 1:\n",
    "        if pcaparam == 0:\n",
    "            if specslopparam == 0:\n",
    "                plt.title('Spectra as two blocks (Group III)')\n",
    "            if specslopparam == 1:\n",
    "                if onlyCXI == 0:\n",
    "                    plt.title('CXI and EI Slopes + Spectra as two blocks (Group XI)')\n",
    "                if onlyCXI == 1:\n",
    "                    plt.title('CXI Slopes + Spectra as two blocks (Group VII)')\n",
    "                    \n",
    "        if pcaparam == 1:\n",
    "            if specslopparam == 0:\n",
    "                plt.title('Spectra as two blocks, PCA (Group IV)')\n",
    "            if specslopparam == 1:\n",
    "                if onlyCXI == 0:\n",
    "                    plt.title('CXI and EI Slopes + Spectra as two blocks, PCA (Group XII)')\n",
    "                if onlyCXI == 1:\n",
    "                    plt.title('CXI Slopes + Spectra as two blocks, PCA (Group VIII)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142eabbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining the dataset of asteroids previously without labels to apply the classification model on them.\n",
    "\"\"\"\n",
    "\n",
    "rest_batch_size = 139\n",
    "\n",
    "if pcaparam == 0:\n",
    "    if specslopparam == 0:\n",
    "        rest_x = spectra_all.drop(taxonomy_spectra.index)\n",
    "        rest_astnum = rest_x.index\n",
    "        X_rest = rest_x.to_numpy()\n",
    "\n",
    "    if specslopparam == 1:\n",
    "        rest_x = spectra_slopes.drop(taxonomy_spectra_slopes.index)\n",
    "        rest_astnum = rest_x.index\n",
    "        X_rest = rest_x.to_numpy()\n",
    "        \n",
    "    if specslopparam == 2:\n",
    "        rest_x = spectra_slopes.drop(taxonomy_slopes.index)\n",
    "        rest_astnum = rest_x.index\n",
    "        X_rest = rest_x.to_numpy()\n",
    "        \n",
    "if pcaparam == 1:\n",
    "    if specslopparam == 0:\n",
    "        rest_x = principal_spectra_all.drop(taxonomy_spectra_pca.index)\n",
    "        rest_astnum = rest_x.index\n",
    "        X_rest = rest_x.to_numpy()\n",
    "\n",
    "    if specslopparam == 1:\n",
    "        rest_x = principal_spectra_slopes.drop(taxonomy_spectra_slopes_pca.index)\n",
    "        rest_astnum = rest_x.index\n",
    "        X_rest = rest_x.to_numpy()\n",
    "        \n",
    "def load_restset(data:float, rest_astnum, dataset_size: int = len(X_rest)):\n",
    "    labels = torch.zeros((dataset_size, 1))\n",
    "    spectradat = torch.tensor(data, dtype = torch.float32)\n",
    "    astnum = torch.tensor([[a] for a in rest_astnum], dtype = torch.int64)\n",
    "    dataset = spectradataset(spectradat, labels, astnum)\n",
    "    return dataset\n",
    "\n",
    "rest_dataset = load_restset(X_rest, rest_astnum)\n",
    "\n",
    "rest_dataloader = DataLoader(dataset = rest_dataset, shuffle = False, batch_size = rest_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad99ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predicting the taxonomic classes for asteroid with no previous labels.\n",
    "\"\"\"\n",
    "\n",
    "out = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_num, items in enumerate(rest_dataloader):\n",
    "        \n",
    "        spectra = items['spectra']\n",
    "        labels = items['labels']\n",
    "        outputs = model(spectra)\n",
    "        _, predictions = torch.max(outputs,1)\n",
    "        \n",
    "        out.append(predictions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3baf6da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Agregating the new predicted labels with existing PCA results and plotting new predicted asteroids into\n",
    "PCA plots for comparison with known-label asteroids.\n",
    "\"\"\"\n",
    "\n",
    "flat_out = [item for sublist in out for item in sublist]\n",
    "flat_out_class = label_encoder.inverse_transform(flat_out)\n",
    "\n",
    "if specslopparam == 0:\n",
    "    rest_x_pca = principal_spectra_all.drop(taxonomy_spectra.index)\n",
    "    rest_x_pca['predicted'] = flat_out_class\n",
    "    \n",
    "if specslopparam == 1:\n",
    "    rest_x_pca = principal_spectra_slopes.drop(taxonomy_spectra_slopes.index)\n",
    "    rest_x_pca['predicted'] = flat_out_class\n",
    "    \n",
    "plot_pred = rest_x_pca.copy()\n",
    "\n",
    "if specslopparam == 0:\n",
    "    sns.scatterplot(data = plot_pred, x = 'principal component 1', y = 'principal component 2', hue = 'predicted', hue_order=taxonomy_spectra_pca['Main class'].unique())\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(data = plot_pred, x = 'principal component 1', y = 'principal component 3', hue = 'predicted', hue_order=taxonomy_spectra_pca['Main class'].unique())\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(data = plot_pred, x = 'principal component 2', y = 'principal component 3', hue = 'predicted', hue_order=taxonomy_spectra_pca['Main class'].unique())\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "\n",
    "if specslopparam == 1:\n",
    "    sns.scatterplot(data = plot_pred, x = 'principal component 1', y = 'principal component 2', hue = 'predicted', hue_order=taxonomy_spectra_slopes_pca['Main class'].unique())\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(data = plot_pred, x = 'principal component 1', y = 'principal component 3', hue = 'predicted', hue_order=taxonomy_spectra_slopes_pca['Main class'].unique())\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(data = plot_pred, x = 'principal component 1', y = 'principal component 4', hue = 'predicted', hue_order=taxonomy_spectra_slopes_pca['Main class'].unique())\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(data = plot_pred, x = 'principal component 2', y = 'principal component 3', hue = 'predicted', hue_order=taxonomy_spectra_slopes_pca['Main class'].unique())\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(data = plot_pred, x = 'principal component 2', y = 'principal component 4', hue = 'predicted', hue_order=taxonomy_spectra_slopes_pca['Main class'].unique())\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(data = plot_pred, x = 'principal component 3', y = 'principal component 4', hue = 'predicted', hue_order=taxonomy_spectra_slopes_pca['Main class'].unique())\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()\n",
    "    \n",
    "if specslopparam == 2:\n",
    "\n",
    "    sns.scatterplot(data = plot_pred, x = 'principal component 1', y = 'principal component 2', hue = 'predicted', hue_order=taxonomy_spectra_slopes_pca['Main class'].unique())\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047fa0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computing statistics of predicted classes to compare with statistics of existing labels.\n",
    "\"\"\"\n",
    "\n",
    "labstats = taxonomy_spectra_slopes['Main class'].value_counts(normalize=True).mul(100)\n",
    "labstats.rename('All classified', inplace = True)\n",
    "\n",
    "labCSXstats = taxonomy_spectra_slopes_pca_SCX['Main class'].value_counts(normalize=True).mul(100)\n",
    "labCSXstats.rename('NN input', inplace = True)\n",
    "\n",
    "predstats = plot_pred['predicted'].value_counts(normalize=True).mul(100)\n",
    "predstats.rename('All predicted', inplace = True)\n",
    "\n",
    "plotstats = pd.DataFrame(labstats)\n",
    "plotstats = plotstats.join(labCSXstats, how = 'outer')\n",
    "plotstats = plotstats.join(predstats, how = 'outer')\n",
    "plotstats=plotstats.reindex(taxonomy_spectra_slopes_pca['Main class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f388c1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plotting the comparison statistics.\n",
    "\"\"\"\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "plotstats.T.plot(kind='bar', stacked=True, color=sns.color_palette())\n",
    "plt.ylabel('%', loc = 'top', rotation = 'horizontal')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(bbox_to_anchor = (1, 1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
